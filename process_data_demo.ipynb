{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9NZlKovcXY5"
      },
      "source": [
        "[GitHub source](https://github.com/ElvisCasco/process_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_KwreGVc0U9",
        "outputId": "7a30e0f6-3bdd-472d-ca03-a69751101a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working directory: c:\\EC\\BSE\\DSDM\\Term 1\\21DM004 Computing for Data Science\\HW7\n"
          ]
        }
      ],
      "source": [
        "# Automatically detect and set working directory\n",
        "import os\n",
        "from pathlib import Path\n",
        "wd = os.getcwd()\n",
        "print(f\"Working directory: {wd}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rt4XV4acBNK",
        "outputId": "ced7fcc8-d216-405e-8d77-f443eea6aacb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ElvisCasco/process_data.git\n",
            "  Cloning https://github.com/ElvisCasco/process_data.git to c:\\users\\ecasc\\appdata\\local\\temp\\pip-req-build-gszftprf\n",
            "  Resolved https://github.com/ElvisCasco/process_data.git to commit eb1c7ae7ed08fcadfa10928b1014f5545750a38f\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: geopy>=2.4.1 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from process_data==0.1.0) (2.4.1)\n",
            "Requirement already satisfied: numpy>=2.3.4 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from process_data==0.1.0) (2.3.4)\n",
            "Requirement already satisfied: pandas>=2.3.3 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from process_data==0.1.0) (2.3.3)\n",
            "Requirement already satisfied: pytest>=8.4.2 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from process_data==0.1.0) (9.0.0)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.1 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from process_data==0.1.0) (1.7.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn<2.0,>=1.1->process_data==0.1.0) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn<2.0,>=1.1->process_data==0.1.0) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn<2.0,>=1.1->process_data==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from geopy>=2.4.1->process_data==0.1.0) (2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=2.3.3->process_data==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=2.3.3->process_data==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=2.3.3->process_data==0.1.0) (2025.2)\n",
            "Requirement already satisfied: colorama>=0.4 in c:\\users\\ecasc\\appdata\\roaming\\python\\python313\\site-packages (from pytest>=8.4.2->process_data==0.1.0) (0.4.6)\n",
            "Requirement already satisfied: iniconfig>=1.0.1 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytest>=8.4.2->process_data==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: packaging>=22 in c:\\users\\ecasc\\appdata\\roaming\\python\\python313\\site-packages (from pytest>=8.4.2->process_data==0.1.0) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytest>=8.4.2->process_data==0.1.0) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in c:\\users\\ecasc\\appdata\\roaming\\python\\python313\\site-packages (from pytest>=8.4.2->process_data==0.1.0) (2.19.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ecasc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.3.3->process_data==0.1.0) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  Running command git clone --filter=blob:none --quiet https://github.com/ElvisCasco/process_data.git 'C:\\Users\\ecasc\\AppData\\Local\\Temp\\pip-req-build-gszftprf'\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade git+https://github.com/ElvisCasco/process_data.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHl4g7MHcVlP",
        "outputId": "f3b33542-8367-4c82-919e-e13ec03289c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "process_data package - Installed from GitHub\n",
            "============================================================\n",
            "Version: 0.3.0\n",
            "Location: c:\\Users\\ecasc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\process_data\\__init__.py\n",
            "\n",
            "Available functions:\n",
            "  1. data_binary\n",
            "  2. data_encoding\n",
            "  3. data_fill_nans\n",
            "  4. data_loader\n",
            "  5. data_remove_nans\n",
            "  6. data_split\n",
            "  7. model_predict\n",
            "  8. model_train_models\n",
            "  9. pred_auc_score\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Import the package (installed from GitHub)\n",
        "import process_data as pdlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import inspect\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"process_data package - Installed from GitHub\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Version: {getattr(pdlib, '__version__', 'unknown')}\")\n",
        "print(f\"Location: {pdlib.__file__}\")\n",
        "print(f\"\\nAvailable functions:\")\n",
        "exports = [n for n in dir(pdlib) if not n.startswith(\"_\")]\n",
        "for i, func in enumerate(exports, 1):\n",
        "    print(f\"  {i}. {func}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd_Q76hzeIiF"
      },
      "source": [
        "## a. Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJkYuixbhNRp"
      },
      "source": [
        "a. Load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vSOtIEudhu1",
        "outputId": "4e2f7511-09d6-4948-b5f6-0e87d40b4183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded successfully. Shape: (10000, 53)\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Prepare a sample CSV\n",
        "csv_path = wd + \"/data/sample_diabetes_mellitus_data.csv\"\n",
        "df = pdlib.data_loader(csv_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1njbDQPeGCN"
      },
      "source": [
        "## b. Test data_loader and data_split:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf4eL7rAhTof"
      },
      "source": [
        "b. Split the data between train and test. (you can use train_test_split from sklearn or any other way)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J4NX-5CeSDd",
        "outputId": "cbcf74da-c816-4d0d-b757-1c1379add35f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 1: data_loader and data_split\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded successfully. Shape: (10000, 53)\n",
            "data_loader: Loaded (10000, 53)\n",
            "Data loaded successfully. Shape: (10000, 53)\n",
            "data_split:\n",
            "Train: (7000, 53) (70.0%)\n",
            "Test: (3000, 53) (30.0%)\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Test data_loader and data_split\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 1: data_loader and data_split\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "df_loaded = pdlib.data_loader(csv_path)\n",
        "print(f\"data_loader: Loaded {df_loaded.shape}\")\n",
        "\n",
        "train_df, test_df = pdlib.data_split(csv_path, test_size=0.3, random_state=42)\n",
        "print(f\"data_split:\")\n",
        "print(f\"Train: {train_df.shape} ({train_df.shape[0]/df_loaded.shape[0]*100:.1f}%)\")\n",
        "print(f\"Test: {test_df.shape} ({test_df.shape[0]/df_loaded.shape[0]*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUoWutD5ec-T"
      },
      "source": [
        "## c. Test data_remove_nans:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSRnFLzLhaaE"
      },
      "source": [
        "c. Remove those rows that contain NaN values in the columns: age, gender, ethnicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUr_z1wjefrz",
        "outputId": "fd815942-c44b-425a-a6c7-0d4fa812d438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 2: data_remove_nans\n",
            "============================================================\n",
            "Before: Train (7000, 53), NaNs=465\n",
            "        Test (3000, 53), NaNs=185\n",
            "After:  Train (6547, 53), NaNs=0\n",
            "        Test (2821, 53), NaNs=0\n",
            "Passed: No NaNs in specified columns\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Test data_remove_nans\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 2: data_remove_nans\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cols_nan = [\"age\", \"gender\", \"ethnicity\"]\n",
        "print(f\"Before: Train {train_df.shape}, NaNs={train_df[cols_nan].isna().sum().sum()}\")\n",
        "print(f\"        Test {test_df.shape}, NaNs={test_df[cols_nan].isna().sum().sum()}\")\n",
        "\n",
        "train_df = pdlib.data_remove_nans(train_df, columns=cols_nan)\n",
        "test_df = pdlib.data_remove_nans(test_df, columns=cols_nan)\n",
        "\n",
        "print(f\"After:  Train {train_df.shape}, NaNs={train_df[cols_nan].isna().sum().sum()}\")\n",
        "print(f\"        Test {test_df.shape}, NaNs={test_df[cols_nan].isna().sum().sum()}\")\n",
        "print(\"Passed: No NaNs in specified columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFnW6IHceptX"
      },
      "source": [
        "## d. Test data_fill_nans:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAsmeoMzhhWU"
      },
      "source": [
        "d. Fill NaN with the mean value of the column in the columns: height, weight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7p-jYjZetVg",
        "outputId": "dc8379a3-c02b-41c6-c7e6-7a573d33ff4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 3: data_fill_nans\n",
            "============================================================\n",
            "Before: {'height': 86, 'weight': 1077}\n",
            "After:  {'height': 0, 'weight': 0}\n",
            "Mean height: 169.98, weight: 86.91\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Test data_fill_nans\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 3: data_fill_nans\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cols_fill = [\"height\", \"weight\"]\n",
        "print(f\"Before: {train_df[cols_fill].isna().sum().to_dict()}\")\n",
        "\n",
        "train_df = pdlib.data_fill_nans(train_df, columns=cols_fill)\n",
        "test_df = pdlib.data_fill_nans(test_df, columns=cols_fill)\n",
        "\n",
        "print(f\"After:  {train_df[cols_fill].isna().sum().to_dict()}\")\n",
        "print(f\"Mean height: {train_df['height'].mean():.2f}, weight: {train_df['weight'].mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-at5k0K-e3SB"
      },
      "source": [
        "## e. Test data_encoding:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Gb-yvGFhrmq"
      },
      "source": [
        "e. Generate dummies for ethnicity column (One hot encoding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNLbr2QZe6RF",
        "outputId": "5c54a1c9-802f-446d-b01a-d31452183b74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 4: data_encoding\n",
            "============================================================\n",
            "Before: 53 columns\n",
            "After:  58 columns\n",
            "New columns: ['ethnicity_African American', 'ethnicity_Asian', 'ethnicity_Caucasian', 'ethnicity_Hispanic', 'ethnicity_Native American', 'ethnicity_Other/Unknown']\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Test data_encoding (one-hot encoding)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 4: data_encoding\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"Before: {train_df.shape[1]} columns\")\n",
        "train_df = pdlib.data_encoding(train_df, columns=[\"ethnicity\"])\n",
        "test_df = pdlib.data_encoding(test_df, columns=[\"ethnicity\"])\n",
        "\n",
        "ethnicity_cols = [c for c in train_df.columns if c.startswith(\"ethnicity_\")]\n",
        "print(f\"After:  {train_df.shape[1]} columns\")\n",
        "print(f\"New columns: {ethnicity_cols}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABOWSYs1fFuS"
      },
      "source": [
        "## f. Test data_binary:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnB3t2Hfhxw5"
      },
      "source": [
        "f. Create a binary variable for gender M/F."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2LsAHrtfIcN",
        "outputId": "e12d43d6-8b54-4e54-ff99-29544f3f2c7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 5: data_binary\n",
            "============================================================\n",
            "Before: gender dtype=object, unique=['F' 'M']\n",
            "After:  gender dtype=Int64, unique=[np.int64(0), np.int64(1)]\n",
            "Value counts:\n",
            "gender\n",
            "1    3599\n",
            "0    2948\n",
            "Name: count, dtype: Int64\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Test data_binary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 5: data_binary\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"Before: gender dtype={train_df['gender'].dtype}, unique={train_df['gender'].unique()}\")\n",
        "train_df = pdlib.data_binary(train_df, column=\"gender\")\n",
        "test_df = pdlib.data_binary(test_df, column=\"gender\")\n",
        "\n",
        "print(f\"After:  gender dtype={train_df['gender'].dtype}, unique={sorted(train_df['gender'].dropna().unique())}\")\n",
        "print(f\"Value counts:\\n{train_df['gender'].value_counts()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR9Uw4GXf2la"
      },
      "source": [
        "## g. Test model_train_models:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXPmlHuHiA7E"
      },
      "source": [
        "g. Train a model (for instance LogisticRegression or RandomForestClassifier from sklearn) in the train data.\n",
        "\n",
        "Use as features the columns: `age`, `height`, `weight`, `aids`, `cirrhosis`, `hepatic_failure`, `immunosuppression`, `leukemia`, `lymphoma`, `solid_tumor_with_metastasis`.\n",
        "\n",
        "Use as target the column: `diabetes_mellitus`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92JAivSXf50G",
        "outputId": "edad77cb-880e-48cd-92c6-f60c46fce993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 6: data_train_models\n",
            "============================================================\n",
            "Training with 10 features, 6547 samples\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained: LogisticRegression\n",
            "Trained: RandomForestClassifier\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Train models\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 6: data_train_models\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "FEATURES = [\n",
        "    \"age\", \"height\", \"weight\",\n",
        "    \"aids\", \"cirrhosis\", \"hepatic_failure\",\n",
        "    \"immunosuppression\", \"leukemia\", \"lymphoma\",\n",
        "    \"solid_tumor_with_metastasis\",\n",
        "]\n",
        "TARGET = \"diabetes_mellitus\"\n",
        "\n",
        "X_train = train_df[FEATURES]\n",
        "y_train = train_df[TARGET]\n",
        "\n",
        "print(f\"Training with {len(FEATURES)} features, {len(X_train)} samples\")\n",
        "model_lr = pdlib.model_train_models(X_train, y_train, model_type=\"logreg\")\n",
        "model_rf = pdlib.model_train_models(X_train, y_train, model_type=\"rf\")\n",
        "\n",
        "print(f\"Trained: {type(model_lr).__name__}\")\n",
        "print(f\"Trained: {type(model_rf).__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBDdiKUDgI9f"
      },
      "source": [
        "## h. Test add_predictions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C3kzsGhieiv"
      },
      "source": [
        "h. Predict the targets for both the train and test sets and add the prediction as a new column (use predict_proba from the model to get the predicted probabilities) name the new column something\n",
        "like predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiOkg5HvgLXg",
        "outputId": "eef07c52-a275-41a9-f676-b5c598258ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 7: add_predictions\n",
            "============================================================\n",
            "Added 'predictions' column to train and test sets\n",
            "\n",
            "Train predictions sample:\n",
            "      diabetes_mellitus  predictions\n",
            "9069                  0     0.133033\n",
            "2603                  0     0.235128\n",
            "7738                  0     0.305614\n",
            "1579                  0     0.168839\n",
            "5058                  0     0.156940\n",
            "\n",
            "Test predictions sample:\n",
            "      diabetes_mellitus  predictions\n",
            "6252                  1     0.317016\n",
            "1731                  0     0.282181\n",
            "4742                  0     0.117664\n",
            "4521                  0     0.130718\n",
            "6340                  1     0.331450\n",
            "\n",
            "Assertion passed\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Add predictions to train and test sets\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 7: add_predictions\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Import add_predictions function\n",
        "try:\n",
        "    add_predictions = pdlib.add_predictions\n",
        "except AttributeError:\n",
        "    from process_data.pred_auc_score import add_predictions\n",
        "\n",
        "# Add predictions using LogisticRegression model\n",
        "train_with_pred, test_with_pred = add_predictions(\n",
        "    model_lr,\n",
        "    train_df,\n",
        "    test_df,\n",
        "    FEATURES,\n",
        "    pred_col=\"predictions\",\n",
        "    inplace=False\n",
        ")\n",
        "\n",
        "print(f\"Added 'predictions' column to train and test sets\")\n",
        "print(f\"\\nTrain predictions sample:\")\n",
        "print(train_with_pred[[TARGET, \"predictions\"]].head())\n",
        "print(f\"\\nTest predictions sample:\")\n",
        "print(test_with_pred[[TARGET, \"predictions\"]].head())\n",
        "\n",
        "assert \"predictions\" in train_with_pred.columns\n",
        "assert \"predictions\" in test_with_pred.columns\n",
        "print(\"\\nAssertion passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuwl2aG6gYNt"
      },
      "source": [
        "## i. Test pred_auc_score:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaLl0bpHi4SD"
      },
      "source": [
        "i. Compute the train and test roc_auc metric using roc_auc_score from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogJSvN4dgbA8",
        "outputId": "959f94d6-0c05-449d-85ac-1bed61e7204a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 8: pred_auc_score (ROC AUC)\n",
            "============================================================\n",
            "ROC AUC (LogisticRegression):\n",
            "   Train AUC: 0.6761\n",
            "   Test AUC:  0.6559\n",
            "   Difference: 0.0202\n",
            "Model performs better than random\n"
          ]
        }
      ],
      "source": [
        "# Cell 10: Compute ROC AUC scores\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 8: pred_auc_score (ROC AUC)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "auc_train = pdlib.pred_auc_score(\n",
        "    train_with_pred[TARGET],\n",
        "    train_with_pred[\"predictions\"]\n",
        ")\n",
        "auc_test = pdlib.pred_auc_score(\n",
        "    test_with_pred[TARGET],\n",
        "    test_with_pred[\"predictions\"]\n",
        ")\n",
        "\n",
        "print(f\"ROC AUC (LogisticRegression):\")\n",
        "print(f\"   Train AUC: {auc_train:.4f}\")\n",
        "print(f\"   Test AUC:  {auc_test:.4f}\")\n",
        "print(f\"   Difference: {abs(auc_train - auc_test):.4f}\")\n",
        "\n",
        "if auc_test > 0.5:\n",
        "    print(f\"Model performs better than random\")\n",
        "else:\n",
        "    print(f\"Model needs improvement\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBFTrRj4gldm"
      },
      "source": [
        "## Test model_predict:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzX-AnDygoGW",
        "outputId": "4eca7fbf-80e7-4a92-e6bc-183ab8455b54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 9: data_predict\n",
            "============================================================\n",
            "Probabilities shape: (2821,)\n",
            "   Sample: [0.31701586 0.28218064 0.11766365 0.13071773 0.33144975]\n",
            "data_predict matches add_predictions\n",
            "Class predictions: [0 0 0 0 0 0 0 0 0 0]\n",
            "   Unique classes: [np.int64(0), np.int64(1)]\n"
          ]
        }
      ],
      "source": [
        "# Cell 11: Test data_predict function\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 9: data_predict\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from numpy.testing import assert_allclose\n",
        "\n",
        "# Test predict_proba\n",
        "proba_test = pdlib.model_predict(model_lr, test_df[FEATURES], proba=True)\n",
        "print(f\"Probabilities shape: {proba_test.shape}\")\n",
        "print(f\"   Sample: {proba_test[:5]}\")\n",
        "\n",
        "# Verify matches add_predictions\n",
        "assert_allclose(proba_test, test_with_pred[\"predictions\"].to_numpy(), atol=1e-9)\n",
        "print(\"data_predict matches add_predictions\")\n",
        "\n",
        "# Test class predictions\n",
        "class_pred = pdlib.model_predict(model_lr, test_df[FEATURES], proba=False)\n",
        "print(f\"Class predictions: {class_pred[:10]}\")\n",
        "print(f\"   Unique classes: {sorted(set(class_pred))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bedC6mFnnZ_A"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkgq75Zxg3ye",
        "outputId": "5f0efc03-6cbd-4f50-8741-e14317cd317d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ALL TESTS COMPLETED SUCCESSFULLY\n",
            "============================================================\n",
            "\n",
            "Functions tested:\n",
            "   1. data_loader\n",
            "   2. data_split\n",
            "   3. data_remove_nans\n",
            "   4. data_fill_nans\n",
            "   5. data_encoding\n",
            "   6. data_binary\n",
            "   7. data_train_models\n",
            "   8. add_predictions\n",
            "   9. pred_auc_score\n",
            "  10. data_predict\n",
            "\n",
            "Final Results:\n",
            "  Dataset size: 9368 samples\n",
            "  Train: 6547 samples\n",
            "  Test:  2821 samples\n",
            "  Features: 10\n",
            "  Train AUC: 0.6761\n",
            "  Test AUC:  0.6559\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 12: Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ALL TESTS COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nFunctions tested:\")\n",
        "functions_tested = [\n",
        "    \"data_loader\", \"data_split\", \"data_remove_nans\",\n",
        "    \"data_fill_nans\", \"data_encoding\", \"data_binary\",\n",
        "    \"data_train_models\", \"add_predictions\",\n",
        "    \"pred_auc_score\", \"data_predict\"\n",
        "]\n",
        "for i, func in enumerate(functions_tested, 1):\n",
        "    print(f\"  {i:2d}. {func}\")\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"  Dataset size: {len(train_with_pred) + len(test_with_pred)} samples\")\n",
        "print(f\"  Train: {len(train_with_pred)} samples\")\n",
        "print(f\"  Test:  {len(test_with_pred)} samples\")\n",
        "print(f\"  Features: {len(FEATURES)}\")\n",
        "print(f\"  Train AUC: {auc_train:.4f}\")\n",
        "print(f\"  Test AUC:  {auc_test:.4f}\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
